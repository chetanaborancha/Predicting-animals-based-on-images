{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\">INFO 6105 Data Science Eng Methods and Tools, Lecture 9</div>\n",
    "<div style=\"text-align: right\">Dino Konstantopoulos, 27 March 2019</div>\n",
    "\n",
    "# Lab: Machine Learning (ML) with Keras\n",
    "\n",
    "In this notebook, we reuse professor's trained weights to recognize images we download from the web. We start with an image of a bird that we selected in class.\n",
    "\n",
    "Steps:\n",
    "- Create folder `saved_models` in your `C:/Users/<username>` folder. In that folder, place pretrained neural weights in [H5 format](https://en.wikipedia.org/wiki/Hierarchical_Data_Format) `keras_cifar10_trained_model.h5`,\n",
    "- In your `C:/Users/<username>/data` folder, download the images used for training from file `cifar-10-batches-py.tar.gz` \n",
    "- Download the picture of a bird  `yellowboard.jpg` and place it in folder `C:/Users/<username>/data`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\1.Northeastern University\\\\Second Semester\\\\Data Science Methods and Tools\\\\Assignments\\\\Assignment 8\\\\001420430_Assignment 8-3_Chetana Borancha'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.abspath('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_classes = 10\n",
    "epochs = 100\n",
    "data_augmentation = True\n",
    "num_predictions = 20\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'keras_cifar10_trained_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# The data, split between train and test sets:\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\boran\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From C:\\Users\\boran\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\boran\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "#model.load_weights('saved_models/keras_cifar10_trained_model.h5')\n",
    "model = load_model(r'C:\\Users\\boran\\saved_models\\keras_cifar10_trained_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should take about a minute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.15.0'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 3s 349us/step\n",
      "Test loss: 168.75168056640624\n",
      "Test accuracy: 0.5636000037193298\n"
     ]
    }
   ],
   "source": [
    "# Score trained model.\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_load_cifar(verbose=False):\n",
    "  import os,shutil\n",
    "  from keras.datasets import cifar10\n",
    "  from keras.utils import to_categorical\n",
    "  \n",
    "  #datadir = os.path.expanduser(\"~\") + \"/.keras/datasets/\"\n",
    "  datadir = \"/data\"\n",
    "  datafile = datadir+\"cifar-10-batches-py.tar.gz\" # the name keras looks for\n",
    "  \n",
    "  #if not os.path.isfile(datafile):\n",
    "  #  os.makedirs(datadir)\n",
    "  #  shutil.copyfile($$ref{{[\"~:output\",\"119210b3-a610-428e-93f2-ad5d987f442b\",\"cifar-10-python.tar.gz\"]}}, datafile)\n",
    "  \n",
    "  # The data, shuffled and split between train and test sets:\n",
    "  (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "  if verbose:\n",
    "    print(\"x_train shape: {}, {} train samples, {} test samples.\\n\".format(\n",
    "      x_train.shape, x_train.shape[0], x_test.shape[0]))\n",
    "  \n",
    "  # Convert class vectors to binary class matrices.\n",
    "  y_train = to_categorical(y_train, num_classes)\n",
    "  y_test = to_categorical(y_test, num_classes)\n",
    "  \n",
    "  x_train = x_train.astype(\"float32\")\n",
    "  x_test = x_test.astype(\"float32\")\n",
    "  x_train /= 255.0\n",
    "  x_test /= 255.0\n",
    "  \n",
    "  # Load label names to use in prediction results\n",
    "  label_list_path = \"datasets/cifar-10-batches-py/batches.meta\"\n",
    "  \n",
    "  keras_dir = os.path.expanduser(os.path.join(\"~\", \".keras\"))\n",
    "  datadir_base = os.path.expanduser(keras_dir)\n",
    "  if not os.access(datadir_base, os.W_OK):\n",
    "    datadir_base = os.path.join(\"/tmp\", \".keras\")\n",
    "  label_list_path = os.path.join(datadir_base, label_list_path)\n",
    "  \n",
    "  with open(label_list_path, mode=\"rb\") as f:\n",
    "    labels = pickle.load(f)\n",
    "  \n",
    "  return x_train, y_train, x_test, y_test, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda install dill\n",
    "import numpy as np\n",
    "import dill as pickle\n",
    "from math import *\n",
    "_,_,_,_,labels = setup_load_cifar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow\n",
    "import keras.backend.tensorflow_backend as K\n",
    "sess = K.get_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting should only take a few seconds! Lets try predicting the below dog image\n",
    "\n",
    "\n",
    "<br />\n",
    "<center>\n",
    "<img src = 'dog1.jpg' />\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dog'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = tensorflow.read_file('dog1.jpg')\n",
    "img = tensorflow.image.decode_jpeg(img, channels=3)\n",
    "img.set_shape([None, None, 3])\n",
    "img = tensorflow.image.resize_images(img, (32, 32))\n",
    "img = img.eval(session=sess) # convert to numpy array\n",
    "img = np.expand_dims(img, 0) # make 'batch' of 1\n",
    "\n",
    "pred = model.predict(img)\n",
    "pred = labels[\"label_names\"][np.argmax(pred)]\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was classified as a dog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />\n",
    "<center>\n",
    "<img src =dog2.jpg width = 800 />\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dog'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = tensorflow.read_file('dog2.jpg')\n",
    "img = tensorflow.image.decode_jpeg(img, channels=3)\n",
    "img.set_shape([None, None, 3])\n",
    "img = tensorflow.image.resize_images(img, (32, 32))\n",
    "img = img.eval(session=sess) # convert to numpy array\n",
    "img = np.expand_dims(img, 0) # make 'batch' of 1\n",
    "\n",
    "pred = model.predict(img)\n",
    "pred = labels[\"label_names\"][np.argmax(pred)]\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />\n",
    "<center>\n",
    "<img src =dog3.jpg width = 800 />\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dog'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = tensorflow.read_file('dog3.jpg')\n",
    "img = tensorflow.image.decode_jpeg(img, channels=3)\n",
    "img.set_shape([None, None, 3])\n",
    "img = tensorflow.image.resize_images(img, (32, 32))\n",
    "img = img.eval(session=sess) # convert to numpy array\n",
    "img = np.expand_dims(img, 0) # make 'batch' of 1\n",
    "\n",
    "pred = model.predict(img)\n",
    "pred = labels[\"label_names\"][np.argmax(pred)]\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />\n",
    "<center>\n",
    "<img src =dog4.jpg width = 800 />\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dog'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = tensorflow.read_file('dog4.jpg')\n",
    "img = tensorflow.image.decode_jpeg(img, channels=3)\n",
    "img.set_shape([None, None, 3])\n",
    "img = tensorflow.image.resize_images(img, (32, 32))\n",
    "img = img.eval(session=sess) # convert to numpy array\n",
    "img = np.expand_dims(img, 0) # make 'batch' of 1\n",
    "\n",
    "pred = model.predict(img)\n",
    "pred = labels[\"label_names\"][np.argmax(pred)]\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />\n",
    "<center>\n",
    "<img src =dog5.jpg width = 800 />\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dog'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = tensorflow.read_file('dog5.jpg')\n",
    "img = tensorflow.image.decode_jpeg(img, channels=3)\n",
    "img.set_shape([None, None, 3])\n",
    "img = tensorflow.image.resize_images(img, (32, 32))\n",
    "img = img.eval(session=sess) # convert to numpy array\n",
    "img = np.expand_dims(img, 0) # make 'batch' of 1\n",
    "\n",
    "pred = model.predict(img)\n",
    "pred = labels[\"label_names\"][np.argmax(pred)]\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />\n",
    "<center>\n",
    "<img src =dog6.jpg width = 800 />\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'horse'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = tensorflow.read_file('dog6.jpg')\n",
    "img = tensorflow.image.decode_jpeg(img, channels=3)\n",
    "img.set_shape([None, None, 3])\n",
    "img = tensorflow.image.resize_images(img, (32, 32))\n",
    "img = img.eval(session=sess) # convert to numpy array\n",
    "img = np.expand_dims(img, 0) # make 'batch' of 1\n",
    "\n",
    "pred = model.predict(img)\n",
    "pred = labels[\"label_names\"][np.argmax(pred)]\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This has been wrongly classified as horse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />\n",
    "<center>\n",
    "<img src =dog7.jpg width = 800 />\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'horse'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = tensorflow.read_file('dog7.jpg')\n",
    "img = tensorflow.image.decode_jpeg(img, channels=3)\n",
    "img.set_shape([None, None, 3])\n",
    "img = tensorflow.image.resize_images(img, (32, 32))\n",
    "img = img.eval(session=sess) # convert to numpy array\n",
    "img = np.expand_dims(img, 0) # make 'batch' of 1\n",
    "\n",
    "pred = model.predict(img)\n",
    "pred = labels[\"label_names\"][np.argmax(pred)]\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrongly classified!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />\n",
    "<center>\n",
    "<img src =dog8.jpg width = 800 />\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'horse'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = tensorflow.read_file('dog8.jpg')\n",
    "img = tensorflow.image.decode_jpeg(img, channels=3)\n",
    "img.set_shape([None, None, 3])\n",
    "img = tensorflow.image.resize_images(img, (32, 32))\n",
    "img = img.eval(session=sess) # convert to numpy array\n",
    "img = np.expand_dims(img, 0) # make 'batch' of 1\n",
    "\n",
    "pred = model.predict(img)\n",
    "pred = labels[\"label_names\"][np.argmax(pred)]\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrongly classified as horse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />\n",
    "<center>\n",
    "<img src =dog9.jpg width = 800 />\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'frog'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = tensorflow.read_file('dog9.jpg')\n",
    "img = tensorflow.image.decode_jpeg(img, channels=3)\n",
    "img.set_shape([None, None, 3])\n",
    "img = tensorflow.image.resize_images(img, (32, 32))\n",
    "img = img.eval(session=sess) # convert to numpy array\n",
    "img = np.expand_dims(img, 0) # make 'batch' of 1\n",
    "\n",
    "pred = model.predict(img)\n",
    "pred = labels[\"label_names\"][np.argmax(pred)]\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrongly classified as Frog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />\n",
    "<center>\n",
    "<img src =gelding-bay-coat.jpg width = 800 />\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'horse'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = tensorflow.read_file('gelding-bay-coat.jpg')\n",
    "img = tensorflow.image.decode_jpeg(img, channels=3)\n",
    "img.set_shape([None, None, 3])\n",
    "img = tensorflow.image.resize_images(img, (32, 32))\n",
    "img = img.eval(session=sess) # convert to numpy array\n",
    "img = np.expand_dims(img, 0) # make 'batch' of 1\n",
    "\n",
    "pred = model.predict(img)\n",
    "pred = labels[\"label_names\"][np.argmax(pred)]\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />\n",
    "<center>\n",
    "<img src =cheetah.jpg width = 800 />\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'frog'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = tensorflow.read_file('cheetah.jpg')\n",
    "img = tensorflow.image.decode_jpeg(img, channels=3)\n",
    "img.set_shape([None, None, 3])\n",
    "img = tensorflow.image.resize_images(img, (32, 32))\n",
    "img = img.eval(session=sess) # convert to numpy array\n",
    "img = np.expand_dims(img, 0) # make 'batch' of 1\n",
    "\n",
    "pred = model.predict(img)\n",
    "pred = labels[\"label_names\"][np.argmax(pred)]\n",
    "pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
